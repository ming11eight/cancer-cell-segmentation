{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMWS2dl77xsVJo6AVDnXmGR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["open in colab 추가"],"metadata":{"id":"gozeARIcxzFD"}},{"cell_type":"markdown","source":["# Segment Anything  \n","  \n","**SAM(Segment Anything Model)**은 점이나 상자와 같은 입력 prompt에서 객체 마스크를 예측하며 이미지의 모든 객체에 대한 마스크를 생성하는 데 사용할 수 있습니다. 1,100만 개의 이미지와 11억 개의 마스크로 구성된 데이터 세트 에 대해 훈련되었으며 다양한 분할 작업에서 강력한 제로샷 성능을 발휘합니다. 이 모델은 이미지나 비디오에 있는 여러 객체들을 정확하게 인식하고 분할하여 각 객체의 경계를 명확하게 파악할 수 있습니다.  \n","\n","![대체 텍스트](https://github.com/facebookresearch/segment-anything/raw/main/assets/model_diagram.png?raw=true)\n","<!-- ![대체 텍스트](https://github.com/facebookresearch/segment-anything/raw/main/assets/notebook1.png?raw=true) -->\n","\n","SAM(Segmentation Anything Model)은 자연 영상 분할에서 놀라운 다양성과 성능을 보여주었으며, 의료 영상 분할에 적용하기 위해 fine-tuning되어 사용되고 있습니다.   \n","  \n","  \n","따라서, SAM을 이용해 보다 쉽게 이미지를 분할하는 방법을 소개한다."],"metadata":{"id":"HFxqv1mznmzP"}},{"cell_type":"markdown","source":["----------"],"metadata":{"id":"CaL8LMXVrhgA"}},{"cell_type":"markdown","source":["## Environment Set-up\n","\n","installation : python>=3.8, pytorch>=1.7, torchvision>=0.8    \n","  \n","  \n","SAM github : https://github.com/facebookresearch/segment-anything.git  \n","\n","MedSAM github : https://github.com/bowang-lab/MedSAM.git"],"metadata":{"id":"eeZiTSHvn-Xn"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"FIuzQdB7nEwB"},"outputs":[],"source":["!pip install git+https://github.com/bowang-lab/MedSAM.git"]},{"cell_type":"code","source":["# !pip install ipympl"],"metadata":{"id":"y_dJuQSyspxB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load Model"],"metadata":{"id":"8pyuViZ1s6Mv"}},{"cell_type":"code","source":["from segment_anything import sam_model_registry\n","from demo import BboxPromptDemo\n","from google.colab import output\n","\n","output.enable_custom_widget_manager()\n","# MedSAM_CKPT_PATH = \"model/sam_vit_b_01ec64.pth\"\n","MedSAM_CKPT_PATH = \"medsam_vit_b.pth\"\n","device = \"cuda:0\"\n","sam_model = sam_model_registry['vit_b'](checkpoint=MedSAM_CKPT_PATH)\n","sam_model = sam_model.to(device)\n","sam_model.eval()"],"metadata":{"id":"pj7U01Ccs9MX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load Data & Run Inference\n","\n","- Button\n","  - clear : prompt 리셋\n","  - save : mask 저장"],"metadata":{"id":"ElPimnRWtFGy"}},{"cell_type":"code","source":["# 데이터 확인\n","import cv2\n","import matplotlib.pyplot as plt\n","\n","img = cv2.imread(\"assets/img_demo.png\")\n","plt.imshow(img)\n","plt.show()"],"metadata":{"id":"qItA1sQBt1mV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img = 'assets/img_demo.png'\n","bbox_prompt_demo = BboxPromptDemo(sam_model)\n","bbox_prompt_demo.show(img)"],"metadata":{"id":"_h3JN5oqtIto"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Mask 확인\n","import cv2\n","import matplotlib.pyplot as plt\n","\n","# img = 'data/test_img.png'\n","mask = cv2.imread('segs.png')\n","mask = cv2.cvtColor(mask, cv2.COLOR_RGB2GRAY)\n","plt.imshow(mask,'gray')\n","plt.show()"],"metadata":{"id":"J6u1EExVtRVY"},"execution_count":null,"outputs":[]}]}